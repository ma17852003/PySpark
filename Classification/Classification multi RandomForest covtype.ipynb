{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fbebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- encoding:utf-8 -*-\n",
    "#-*- coding: cp950 -*-\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from numpy import concatenate\n",
    "from pandas import concat\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import col  \n",
    "import pyspark.sql.types\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from pyspark import since, SparkContext, keyword_only\n",
    "\n",
    "from pyspark.ml.common import _java2py, _py2java\n",
    "from pyspark.ml.wrapper import _jvm\n",
    "from pyspark.ml.util import *\n",
    "from pyspark.ml.wrapper import JavaEstimator, JavaModel\n",
    "from pyspark.ml.param.shared import *\n",
    "from pyspark.ml.common import inherit_doc\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.feature import QuantileDiscretizer, VectorSlicer\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder,VectorAssembler\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "from pyspark.ml.stat import Correlation, ChiSquareTest\n",
    "from pyspark.ml.stat import Summarizer\n",
    "\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.feature import DCT\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder, Normalizer, StandardScaler\n",
    "from pyspark.ml.feature import MinMaxScaler, MaxAbsScaler, Bucketizer\n",
    "from pyspark.ml.feature import ElementwiseProduct\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.ml.fpm import PrefixSpan\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.clustering import KMeans, KMeansModel\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml.clustering import PowerIterationClustering\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import LogisticRegression , OneVsRest\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.regression import AFTSurvivalRegression\n",
    "from pyspark.ml.regression import IsotonicRegression\n",
    "from pyspark.ml.regression import FMRegressor\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark.mllib.fpm import FPGrowth\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.classification import LogisticRegressionModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.regression import StreamingLinearRegressionWithSGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6baa1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#數據集:  covtype森林覆蓋\n",
    "#無欄位名稱的橫列\n",
    "#第1欄位:編碼, 有12個屬性\n",
    "#第2至11欄位是數值型, \n",
    "#其他是二元類別型\n",
    "#最後一個是Y結果變數Cover_Type,有7個屬性值 integer: 1 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a8846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/26 07:30:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f4918e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 07:30:53 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 581012\n",
      "+----+---+---+---+---+----+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "| _c0|_c1|_c2|_c3|_c4| _c5|_c6|_c7|_c8| _c9|_c10|_c11|_c12|_c13|_c14|_c15|_c16|_c17|_c18|_c19|_c20|_c21|_c22|_c23|_c24|_c25|_c26|_c27|_c28|_c29|_c30|_c31|_c32|_c33|_c34|_c35|_c36|_c37|_c38|_c39|_c40|_c41|_c42|_c43|_c44|_c45|_c46|_c47|_c48|_c49|_c50|_c51|_c52|_c53|_c54|\n",
      "+----+---+---+---+---+----+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|2596| 51|  3|258|  0| 510|221|232|148|6279|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   5|\n",
      "|2590| 56|  2|212| -6| 390|220|235|151|6225|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   5|\n",
      "|2804|139|  9|268| 65|3180|234|238|135|6121|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   2|\n",
      "+----+---+---+---+---+----+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtt= spark.read.format('csv').option(\"header\",'false').load(\"/home/jovyan/work/pySpark/pySpark_james/data/covtype.csv\")\n",
    "print('data:',dtt.count() )\n",
    "dtt.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647ad0b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      " |-- _c34: string (nullable = true)\n",
      " |-- _c35: string (nullable = true)\n",
      " |-- _c36: string (nullable = true)\n",
      " |-- _c37: string (nullable = true)\n",
      " |-- _c38: string (nullable = true)\n",
      " |-- _c39: string (nullable = true)\n",
      " |-- _c40: string (nullable = true)\n",
      " |-- _c41: string (nullable = true)\n",
      " |-- _c42: string (nullable = true)\n",
      " |-- _c43: string (nullable = true)\n",
      " |-- _c44: string (nullable = true)\n",
      " |-- _c45: string (nullable = true)\n",
      " |-- _c46: string (nullable = true)\n",
      " |-- _c47: string (nullable = true)\n",
      " |-- _c48: string (nullable = true)\n",
      " |-- _c49: string (nullable = true)\n",
      " |-- _c50: string (nullable = true)\n",
      " |-- _c51: string (nullable = true)\n",
      " |-- _c52: string (nullable = true)\n",
      " |-- _c53: string (nullable = true)\n",
      " |-- _c54: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ac45b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 07:31:18 WARN MemoryStore: Not enough space to cache rdd_24_0 in memory! (computed 132.2 MiB so far)\n",
      "21/07/26 07:31:18 WARN BlockManager: Persisting block rdd_24_0 to disk instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+--------+--------+-----+-----+----------+\n",
      "|  海拔|方位|斜率|垂直距離|水平距離| 陰影|label|prediction|\n",
      "+------+----+----+--------+--------+-----+-----+----------+\n",
      "|1859.0|18.0|12.0|    67.0|    11.0| 90.0|  2.0|       2.0|\n",
      "|1872.0|35.0|21.0|   120.0|    18.0| 85.0|  5.0|       2.0|\n",
      "|1877.0|19.0|18.0|    85.0|    25.0|108.0|  2.0|       2.0|\n",
      "|1877.0|28.0|22.0|   127.0|    35.0| 85.0|  5.0|       2.0|\n",
      "|1880.0|34.0|20.0|   124.0|    17.0| 90.0|  5.0|       2.0|\n",
      "|1883.0|27.0|24.0|   120.0|    24.0|108.0|  5.0|       2.0|\n",
      "|1885.0|30.0|19.0|   134.0|    35.0|162.0|  2.0|       2.0|\n",
      "|1888.0| 9.0|25.0|   120.0|    32.0| 90.0|  5.0|       2.0|\n",
      "|1888.0|17.0|19.0|   127.0|    36.0|150.0|  2.0|       2.0|\n",
      "|1888.0|33.0|22.0|   150.0|    46.0|108.0|  5.0|       2.0|\n",
      "+------+----+----+--------+--------+-----+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.668781081034788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "featuresCols=dtt.columns[:54]\n",
    "df= dtt.select([ col(column).cast(\"double\").alias(column) \n",
    "    for column in dtt.columns])\n",
    "df=df.withColumn(\"label\", df[\"_c54\"] -1).drop(\"_c54\") \n",
    "train_df, test_df = df.randomSplit([0.7, 0.3])\n",
    "train_df.cache()\n",
    "test_df.cache()\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"features\")\n",
    "mod= RandomForestClassifier(labelCol=\"label\",featuresCol='features')#,maxDepth =5,maxBins=20)\n",
    "PL= Pipeline(stages=[vectorAssembler,mod])\n",
    "PLmod=PL.fit(train_df)\n",
    "pred= PLmod.transform(test_df)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "                            labelCol=\"label\", predictionCol=\"prediction\", \n",
    "                            metricName=\"accuracy\")\n",
    "pred=PLmod.transform(test_df)\n",
    "res=pred.withColumnRenamed(\"_c0\", \"海拔\") \\\n",
    "    .withColumnRenamed(\"_c1\", \"方位\") \\\n",
    "     .withColumnRenamed(\"_c2\", \"斜率\") \\\n",
    "    .withColumnRenamed(\"_c3\", \"垂直距離\") \\\n",
    "   .withColumnRenamed(\"_c4\", \"水平距離\") \\\n",
    "   .withColumnRenamed(\"_c5\", \"陰影\")           \n",
    "res.select(\"海拔\",\"方位\",\"斜率\",\"垂直距離\" , \"水平距離\",\"陰影\",\"label\",\"prediction\").show(10)\n",
    "accuracy = evaluator.evaluate(pred)\n",
    "print('Accuracy=',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0ec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ea074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb6709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612beb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
